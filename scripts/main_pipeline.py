#!/usr/bin/env python3
"""
End-to-end ML pipeline for binary sentiment classification.
Fully automated, no hardcoded filenames.

Steps:
1. Download dataset from Kaggle
2. Automatically detect main CSV file
3. Normalize data ‚Üí ensure 'text' and 'label' columns
4. Run EDA ‚Üí save visualizations and stats
5. Split into train/test
6. Train best model (LinearSVC + SentenceTransformer)
7. Evaluate on test ‚Üí compute and save metrics
8. Retrain final model on full dataset ‚Üí save weights
"""

import os
import sys
import json
import pandas as pd
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score,
    precision_score,
    recall_score,
    f1_score,
    roc_auc_score
)

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Import your modules
from src.data.download import download_kaggle_dataset
from src.data.utils import normalize_dataset
from src.data.eda import generate_eda_report
from src.models.classifier import SentimentClassifier


# === CONFIGURATION ===
DATASET_NAME = "https://www.kaggle.com/datasets/yaseminkh/ru-eng-sentiment-analysis" 

# –ö–æ–ª–æ–Ω–∫–∏ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (—É—Ç–æ—á–Ω–∏ –ø–æ —Ä–µ–∞–ª—å–Ω–æ–º—É CSV!)
ORIGINAL_TEXT_COLUMN = "text"      # ‚Üê –Ω–∞–ø—Ä–∏–º–µ—Ä: "review", "comment", "text"
ORIGINAL_LABEL_COLUMN = "target"  # ‚Üê –Ω–∞–ø—Ä–∏–º–µ—Ä: "rating", "label", "sentiment"

# –ú–∞–ø–ø–∏–Ω–≥ –º–µ—Ç–æ–∫ ‚Üí 0/1 (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
LABEL_MAPPING = {"negative":-1, "positive":1}

# Paths (–±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤!)
DATA_DIR = Path("data")
RAW_DATA_DIR = DATA_DIR / "raw"
NORMALIZED_DATA_PATH = "" #Path("data/norm_dataset.csv")
# TEST_DATA_PATH = Path("data/test.csv")
REPORTS_DIR = DATA_DIR / "reports"
MODEL_DIR = Path("models/weights")
FINAL_MODEL_PATH = MODEL_DIR / "sentiment_model.joblib"
METRICS_PATH = REPORTS_DIR / "metrics.json"


def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ end-to-end –ø–∞–π–ø–ª–∞–π–Ω–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n")

    # --- 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ---
    RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)
    REPORTS_DIR.mkdir(parents=True, exist_ok=True)
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    dataset_file_csv = RAW_DATA_DIR / Path(
        str(DATASET_NAME).replace('https://www.kaggle.com/datasets/', '').split('/')[-1].replace('-', '_') + '.csv'
        )
    dataset_file_xlsx = RAW_DATA_DIR / Path(
        str(DATASET_NAME).replace('https://www.kaggle.com/datasets/', '').split('/')[-1].replace('-', '_') + '.xlsx')

    
    print(dataset_file_csv, dataset_file_xlsx)
    if not os.path.exists(dataset_file_csv):
        if not os.path.exists(dataset_file_xlsx):
            # --- 2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ + –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ CSV ---
            print("üì• –®–∞–≥ 1: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle –∏ –ø–æ–∏—Å–∫ CSV-—Ñ–∞–π–ª–∞...")
            raw_data_path = download_kaggle_dataset(
                dataset_name=DATASET_NAME,
                output_dir=str(RAW_DATA_DIR),
                extract=True
            )
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–π–ª: {raw_data_path}")
        else:
            raw_data_path = dataset_file_xlsx
    else:
        raw_data_path = dataset_file_csv
        
    # --- 3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã ---
    print("üßπ –®–∞–≥ 2: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (–ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ 'text' –∏ 'label')...")
    df = normalize_dataset(
        input_path=str(raw_data_path),
        output_path=str(NORMALIZED_DATA_PATH) if NORMALIZED_DATA_PATH!="" else 'norm_'+str(raw_data_path),
        text_column=ORIGINAL_TEXT_COLUMN,
        label_column=ORIGINAL_LABEL_COLUMN,
        label_mapping=LABEL_MAPPING,
        input_sep=",",
        output_sep=","
    )

    # --- 4-5. –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö + EDA ---
    print("üìä –®–∞–≥ 3: –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ EDA...")
    generate_eda_report(
        df, 
        report_dir=REPORTS_DIR,
        text_col= ORIGINAL_TEXT_COLUMN,
        label_col=ORIGINAL_LABEL_COLUMN,
        sep=','
    )
    
    # --- 6. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test ---
    print("SplitOptions: 80/20, —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –º–µ—Ç–∫–µ...")
    train_df, test_df = train_test_split(
        df,
        test_size=0.2,
        random_state=42,
        stratify=df["label"]
    )
    
    TEST_DATA_PATH = DATA_DIR / Path("test"+ str(raw_data_path).split('/')[-1].split('.')[0]+'.csv')
    test_df.to_csv(TEST_DATA_PATH, index=False, encoding='utf-8')

    # --- 7. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    X_train = train_df["text"].tolist()
    y_train = train_df["label"].tolist()

    X_test = test_df["text"].tolist()
    y_test = test_df["label"].tolist()

    # --- 8. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
    print("üß† –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (LinearSVC + SentenceTransformer)...")
    model = SentimentClassifier()
    model.fit(X_train, y_train)

    # --- 9. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–µ ---
    print("üìà –®–∞–≥ 5: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ...")
    y_pred_str = model.predict(X_test, LABEL_MAPPING)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —á–∏—Å–ª–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    pred_to_int = LABEL_MAPPING#{v: k for k, v in LABEL_MAPPING.items()} #{"negative": 0, "positive": 1}
    y_pred = [pred_to_int[p] for p in y_pred_str]

    # --- 10. –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ ---
    print("üìä –®–∞–≥ 6: –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫...")
    metrics = {
        "accuracy": float(accuracy_score(y_test, y_pred)),
        "precision": float(precision_score(y_test, y_pred)),
        "recall": float(recall_score(y_test, y_pred)),
        "f1": float(f1_score(y_test, y_pred)),
        "roc_auc": float(roc_auc_score(y_test, y_pred))
    }

    print("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    for name, value in metrics.items():
        print(f"  {name}: {value:.4f}")

    # --- 11. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ ---
    with open(METRICS_PATH, "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=4)
    print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {METRICS_PATH}")

    # # --- 12. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ ---
    # print("üîÑ –®–∞–≥ 7: –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    # X_full = df["text"].tolist()
    # y_full = df["label"].tolist()
    # final_model = SentimentClassifier()
    # final_model.fit(X_full, y_full)

    # --- 13. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
    FINAL_MODEL_PATH = MODEL_DIR / "sentiment_model.joblib"
    if FINAL_MODEL_PATH.exists():
        print("File already exists!")
        MODEL_PATH, MODEL_format = str(FINAL_MODEL_PATH).split('/')[-1].split('.')
        if MODEL_PATH[-1].isdigit():
            version = int(MODEL_PATH[-1]) + 1
        else:
            version = 2
        new_filename = MODEL_PATH[:-1] + str(version) + '.' + MODEL_format
        FINAL_MODEL_PATH = MODEL_DIR / new_filename
        print(f"Saving new version as: {FINAL_MODEL_PATH}")
 
    final_model = model
    final_model.save_model(str(FINAL_MODEL_PATH))
    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {FINAL_MODEL_PATH}")

    print("\nüéâ –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω! –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω—ã.")


if __name__ == "__main__":
    main()