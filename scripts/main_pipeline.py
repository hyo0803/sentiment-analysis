#!/usr/bin/env python3
"""
End-to-end pipeline for sentiment classification using SentenceTransformer + LinearSVC.
Steps:
1. Download dataset from Kaggle
2. Validate and normalize structure (ensure 'text' and 'label' columns)
3. Run EDA
4. Split into train/test
5. Train model on train
6. Evaluate on test ‚Üí save metrics
7. Retrain final model on full dataset ‚Üí save
"""

import os
import sys
import json
import pandas as pd 
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score

# –î–æ–±–∞–≤–ª—è–µ–º src –≤ –ø—É—Ç—å
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))
from src.setup import ensure_dependencies, ensure_kaggle_config
from src.data.download import download_kaggle_dataset  as download_dataset_from_kaggle
from src.data.utils import normalize_dataset as validate_and_normalize_data
from src.data.eda import generate_eda_report as run_eda
from src.models.classifier import SentimentClassifier


# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
DATASET_NAME = "utkarshx27/anime-recommendation-dataset"  # ‚Üê –ó–ê–ú–ï–ù–ò –ù–ê –°–í–û–ô!
DATASET_FILE = "anime_recommendation_dataset.csv"
TEXT_COLUMN = "text"
TARGET_COLUMN = "label"  # –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å "positive"/"negative"

RAW_DATA_PATH = Path("data") / DATASET_FILE
PROCESSED_DATA_PATH = Path("data/raw/norm_anime_data.csv")
TEST_DATA_PATH = Path("data/test.csv")
REPORTS_DIR = Path("data/reports")
MODEL_DIR = Path("model_weights")
FINAL_MODEL_PATH = MODEL_DIR / "sentiment_model.joblib"
METRICS_PATH = REPORTS_DIR / "metrics.json"


def label_to_int(label):
    return 1 if label == "positive" else 0


def main():
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    ensure_dependencies()      # —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç kaggle, pandas –∏ –¥—Ä., –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    ensure_kaggle_config()     # –∫–æ–ø–∏—Ä—É–µ—Ç kaggle.json –≤ ~/.kaggle/
    
    print("–ó–∞–ø—É—Å–∫ end-to-end –ø–∞–π–ø–ª–∞–π–Ω–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n")
    # 1. –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    RAW_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)
    REPORTS_DIR.mkdir(parents=True, exist_ok=True)
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    # 2. –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    print("–®–∞–≥ 1: –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle...")
    download_dataset_from_kaggle(
        dataset_name=DATASET_NAME,
        output_path=RAW_DATA_PATH
    )

    # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    print("üßπ –®–∞–≥ 2: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    df = validate_and_normalize_data(
        input_path=RAW_DATA_PATH,
        text_column=TEXT_COLUMN,
        target_column=TARGET_COLUMN,
        output_path=PROCESSED_DATA_PATH
    )

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ target ‚Äî —Å—Ç—Ä–æ–∫–∏ "positive"/"negative"
    assert df[TARGET_COLUMN].isin(["positive", "negative"]).all(), \
        "–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–æ–ª–∂–Ω–∞ —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–æ–ª—å–∫–æ 'positive' –∏–ª–∏ 'negative'"

    # 4. EDA
    print("–®–∞–≥ 3: –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ EDA...")
    run_eda(df, output_dir=REPORTS_DIR)

    # 5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    print("SplitOptions: 80/20, stratify –ø–æ sentiment...")
    train_df, test_df = train_test_split(
        df,
        test_size=0.2,
        random_state=42,
        stratify=df[TARGET_COLUMN]
    )
    test_df.to_csv(TEST_DATA_PATH, index=False)

    # 6. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    X_train = train_df[TEXT_COLUMN].tolist()
    y_train_str = train_df[TARGET_COLUMN].tolist()
    y_train = [label_to_int(y) for y in y_train_str]

    X_test = test_df[TEXT_COLUMN].tolist()
    y_test_str = test_df[TARGET_COLUMN].tolist()
    y_test = [label_to_int(y) for y in y_test_str]

    # 7. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ train
    print("üß† –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    model = SentimentClassifier()
    model.fit(X_train, y_train)

    # 8. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test
    print("üìà –®–∞–≥ 5: –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    y_pred_str = model.predict(X_test)
    y_pred = [label_to_int(y) for y in y_pred_str]

    # 9. –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫
    metrics = {
        "accuracy": float(accuracy_score(y_test, y_pred)),
        "f1": float(f1_score(y_test, y_pred)),
        "precision": float(precision_score(y_test, y_pred)),
        "recall": float(recall_score(y_test, y_pred)),
        "roc_auc": float(roc_auc_score(y_test, y_pred))
    }
    print(f"–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–µ: {json.dumps(metrics, indent=2)}")

    # 10. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    with open(METRICS_PATH, "w", encoding="utf-8") as f:
        json.dump(metrics, f, indent=4)
    print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {METRICS_PATH}")

    # 11. –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
    print("üîÑ –®–∞–≥ 6: –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    X_full = df[TEXT_COLUMN].tolist()
    y_full = [label_to_int(y) for y in df[TARGET_COLUMN].tolist()]
    final_model = SentimentClassifier()
    final_model.fit(X_full, y_full)

    # 12. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    final_model.save_model(FINAL_MODEL_PATH)
    print(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {FINAL_MODEL_PATH}")

    print("\nüéâ –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω!")


if __name__ == "__main__":
    main()