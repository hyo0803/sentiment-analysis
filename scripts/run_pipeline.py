#!/usr/bin/env python3
"""
End-to-end ML pipeline for binary sentiment classification.
Fully automated, no hardcoded filenames.

Steps:
1. Download dataset from Kaggle
2. Automatically detect main CSV file
3. Normalize data ‚Üí ensure 'text' and 'label' columns
4. Run EDA ‚Üí save visualizations and stats
5. Split into train/test
6. Train best model (SentenceTransformer + LinearSVC)
7. Evaluate on test ‚Üí compute and save metrics
8. Retrain final model on full dataset ‚Üí save weights

Usage: python -m scripts.main_pipeline

#################################################################################
End-to-end –ø–∞–π–ø–ª–∞–π–Ω –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
–ü–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –±–µ–∑ –∂—ë—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω—ã—Ö –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤.

–®–∞–≥–∏:
1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å Kaggle
2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞
3. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ‚Üí –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ 'text' –∏ 'label'
4. –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ EDA ‚Üí —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
6. –û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (SentenceTransformer + LinearSVC)
7. –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ ‚Üí –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
8. –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ ‚Üí —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python -m scripts.main_pipeline
"""

import sys
import re
import pandas as pd # type: ignore
from pathlib import Path
from sklearn.model_selection import train_test_split # type: ignore
import numpy as np # type: ignore

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# Import your modules
from src.data.download import download_kaggle_dataset
from src.data.utils import normalize_dataset
from src.data.eda import generate_eda_report, compute_classification_metrics
from src.models.classifier import SentimentClassifier
from src.config.utils import load_config

# === CONFIGURATION (loaded from config/params.yaml via load_config) ===
cfg = load_config() or {}

# dataset
DATASET_NAME = cfg.get("dataset", {}).get("name", "https://www.kaggle.com/datasets/yaseminkh/ru-eng-sentiment-analysis")

# columns
ORIGINAL_TEXT_COLUMN = cfg.get("columns", {}).get("text", "text")
ORIGINAL_LABEL_COLUMN = cfg.get("columns", {}).get("label", "target")

# label mappings / cleaning
LABEL_MAPPING = cfg.get("label_mapping", {-1: 0, 1: 1})
LABEL_TEXT_MAPPING = cfg.get("label_text_mapping", {0: "negative", 1: "positive"})
CLEAR_EXTRA_CLASSES = cfg.get("clear_extra_classes", True)

# paths
paths_cfg = cfg.get("paths", {}) or {}
DATA_DIR = Path(paths_cfg.get("data_dir", "data"))
RAW_DATA_DIR = Path(paths_cfg.get("raw_data_dir", str(DATA_DIR / "raw")))
NORMALIZED_DATA_PATH = paths_cfg.get("normalized_data_path", "")
REPORTS_DIR = Path(paths_cfg.get("reports_dir", str(DATA_DIR / "reports")))
MODEL_DIR = Path(paths_cfg.get("model_dir", "models/weights"))
FINAL_MODEL_PATH = Path(paths_cfg.get("final_model_path", str(MODEL_DIR / "sentiment_model.joblib")))
METRICS_PATH = Path(paths_cfg.get("metrics_path", str(REPORTS_DIR / "metrics.json")))

# split params
SPLIT_CFG = cfg.get("split", {}) or {}
TEST_SIZE = float(SPLIT_CFG.get("test_size", 0.2))
RANDOM_STATE = int(SPLIT_CFG.get("random_state", 42))
STRATIFY = bool(SPLIT_CFG.get("stratify", True))


def main():
    print("| –ó–∞–ø—É—Å–∫ end-to-end –ø–∞–π–ø–ª–∞–π–Ω–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n")

    # --- 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ---
    RAW_DATA_DIR.mkdir(parents=True, exist_ok=True)
    REPORTS_DIR.mkdir(parents=True, exist_ok=True)
    MODEL_DIR.mkdir(parents=True, exist_ok=True)

    print("|- –®–∞–≥ 1: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    # === –ù–æ–≤—ã–π —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –≤—ã–±–æ—Ä–∞ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö ===
    print("|-- –ü–æ–∏—Å–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ / –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")

    allowed_exts = {".csv", ".xlsx"}
    norm_candidate = None
    raw_data_path = None

    # 1) –ï—Å–ª–∏ —è–≤–Ω–æ —É–∫–∞–∑–∞–Ω NORMALIZED_DATA_PATH –∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
    if NORMALIZED_DATA_PATH:
        p = Path(NORMALIZED_DATA_PATH)
        if p.exists() and p.suffix.lower() in allowed_exts:
            norm_candidate = p
            print(f"|--- –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {norm_candidate}")
        elif p.exists():
            print(f"|--- –£–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –Ω–∞–π–¥–µ–Ω, –Ω–æ —Ñ–æ—Ä–º–∞—Ç '{p.suffix}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –û–∂–∏–¥–∞–µ—Ç—Å—è .csv –∏–ª–∏ .xlsx")

    # 2) –ò—â–µ–º –ª—é–±—ã–µ norm_*.csv/xlsx –≤ RAW_DATA_DIR (–≤–Ω–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç NORMALIZED_DATA_PATH)
    if norm_candidate is None:
        csv_matches = sorted(RAW_DATA_DIR.glob("norm_*.csv"))
        xlsx_matches = sorted(RAW_DATA_DIR.glob("norm_*.xlsx"))
        matches = csv_matches + xlsx_matches
        if matches:
            norm_candidate = matches[0]
            print(f"|--- –ù–∞–π–¥–µ–Ω –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {norm_candidate}")

    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –∏—Å—Ö–æ–¥–Ω—ã–π –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–æ–≤
    if norm_candidate is not None:
        raw_data_path = norm_candidate
        normalized_output_path = norm_candidate
        print(f"|--- –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª: {raw_data_path}")
    else:
        # 3) –ò—â–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ RAW_DATA_DIR:
        base_name = str(DATASET_NAME).replace('https://www.kaggle.com/datasets/', '').split('/')[-1]
        derived_csv = RAW_DATA_DIR / (base_name.replace('-', '_') + '.csv')
        derived_xlsx = RAW_DATA_DIR / (base_name.replace('-', '_') + '.xlsx')

        if derived_csv.exists():
            raw_data_path = derived_csv
            print(f"|--- –ù–∞–π–¥–µ–Ω –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π CSV: {raw_data_path}")
        elif derived_xlsx.exists():
            raw_data_path = derived_xlsx
            print(f"|--- –ù–∞–π–¥–µ–Ω –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π XLSX: {raw_data_path}")
        else:
            # fallback: –ª—é–±–æ–π CSV/XLSX –≤ –ø–∞–ø–∫–µ raw (–∏—Å–∫–ª—é—á–∞—è norm_*)
            other_csv = next(RAW_DATA_DIR.glob("*.csv"), None)
            other_xlsx = next(RAW_DATA_DIR.glob("*.xlsx"), None)
            if other_csv and not other_csv.name.startswith("norm_"):
                raw_data_path = other_csv
                print(f"|--- –ù–∞–π–¥–µ–Ω –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π CSV (fallback): {raw_data_path}")
            elif other_xlsx and not other_xlsx.name.startswith("norm_"):
                raw_data_path = other_xlsx
                print(f"|--- –ù–∞–π–¥–µ–Ω –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π XLSX (fallback): {raw_data_path}")

        # 4) –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Å–∫–∞—á–∞—Ç—å —Å Kaggle
        if raw_data_path is None:
            print("|--- –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ ‚Äî —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Å Kaggle...")
            downloaded = download_kaggle_dataset(
                dataset_name=DATASET_NAME,
                output_dir=str(RAW_DATA_DIR),
                extract=True
            )
            raw_data_path = Path(downloaded)
            # –ï—Å–ª–∏ —Å–∫–∞—á–∞–Ω –ø—É—Ç—å ‚Äî –µ—Å–ª–∏ —ç—Ç–æ –ø–∞–ø–∫–∞/–∞—Ä—Ö–∏–≤, –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –Ω–∞–π—Ç–∏ CSV/XLSX –≤–Ω—É—Ç—Ä–∏
            if raw_data_path.is_dir():
                # –∏—â–µ–º –ø–µ—Ä–≤—ã–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —Ñ–∞–π–ª—ã
                cand = next(raw_data_path.glob("*.csv"), None) or next(raw_data_path.glob("*.xlsx"), None)
                if cand:
                    raw_data_path = cand
            print(f"|--- –ü–æ–ª—É—á–µ–Ω —Ñ–∞–π–ª: {raw_data_path}")

        # 5) –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª
        normalized_output_path = Path(NORMALIZED_DATA_PATH) if NORMALIZED_DATA_PATH else (RAW_DATA_DIR / f"norm_{raw_data_path.name}")
        print(f"|-- –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {normalized_output_path}")

        df = normalize_dataset(
            input_path=str(raw_data_path),
            output_path=str(normalized_output_path),
            text_column=ORIGINAL_TEXT_COLUMN,
            clear_extra_classes=CLEAR_EXTRA_CLASSES,
            label_column=ORIGINAL_LABEL_COLUMN,
            label_mapping=LABEL_MAPPING,
            input_sep=",",
            output_sep=","
        )
        # —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ raw_data_path —É–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–ø–µ—Ä—å –Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–∏—Ö —à–∞–≥–æ–≤
        raw_data_path = normalized_output_path

    # –ï—Å–ª–∏ norm_candidate –±—ã–ª –Ω–∞–π–¥–µ–Ω —Ä–∞–Ω–µ–µ, –≤—Å—ë –µ—â—ë –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å DataFrame (–µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω)
    if 'df' not in locals():
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ df
        df = pd.read_csv(raw_data_path) if raw_data_path.suffix.lower() == ".csv" else pd.read_excel(raw_data_path)

    # --- 4-5. –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö + EDA ---
    print("|- –®–∞–≥ 3: –ü—Ä–æ–≤–µ–¥–µ–Ω–∏–µ EDA...")
    generate_eda_report(
        df, 
        report_dir=REPORTS_DIR,
        text_col=ORIGINAL_TEXT_COLUMN,
        label_col=ORIGINAL_LABEL_COLUMN,
        sep=','
    )
    
    # --- 6. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test ---
    print(f"|- –®–∞–≥ 4: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏ (test_size={TEST_SIZE}, random_state={RANDOM_STATE}, stratify={STRATIFY}...)")
    stratify_col = df[ORIGINAL_LABEL_COLUMN] if STRATIFY else None
    train_df, test_df = train_test_split(
        df,
        test_size=TEST_SIZE,
        random_state=RANDOM_STATE,
        stratify=stratify_col
    )
    TRAIN_DATA_PATH = DATA_DIR / Path("train"+ str(raw_data_path).split('/')[-1].split('.')[0]+'.csv')
    print(f"|-- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –≤: {TRAIN_DATA_PATH}")
    train_df.to_csv(TRAIN_DATA_PATH, index=False, encoding='utf-8')

    TEST_DATA_PATH = DATA_DIR / Path("test"+ str(raw_data_path).split('/')[-1].split('.')[0]+'.csv')
    print(f"|-- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –≤: {TEST_DATA_PATH}")
    test_df.to_csv(TEST_DATA_PATH, index=False, encoding='utf-8')

    # --- 7. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    X_train = train_df[ORIGINAL_TEXT_COLUMN].values
    y_train = train_df[ORIGINAL_LABEL_COLUMN].values

    X_test = test_df[ORIGINAL_TEXT_COLUMN].values
    y_test = test_df[ORIGINAL_LABEL_COLUMN].values

    # --- 8. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
    print("|- –®–∞–≥ 5: –û–±—É—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ (SentenceTransformer + LinearSVC)...")
    model = SentimentClassifier()
    model.fit(X_train, y_train)

    # --- 9. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–µ ---
    print("|- –®–∞–≥ 6: –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ...")
    y_pred = model.predict(X_test)

    # –ü–æ–ª—É—á–∞–µ–º —Å–∫–æ—Ä/–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è –ø–æ–∑–∏—Ç–∏–≤–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
    try:
        y_proba = model.predict_proba(X_test)
        y_proba_arr = np.asarray(y_proba)
        if y_proba_arr.ndim == 2 and y_proba_arr.shape[1] >= 2:
            # –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ [class0, class1]
            y_score = y_proba_arr[:, 1]
        else:
            # single-column probabilities (positive class) –∏–ª–∏ flat array
            y_score = y_proba_arr.ravel()
    except Exception:
        try:
            y_score = model.decision_function(X_test)
            y_score = np.asarray(y_score).ravel()
        except Exception:
            # fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–∞–∫ —Å–∫–æ—Ä (–ø–ª–æ—Ö–æ, –Ω–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ—Å—á–∏—Ç–∞—Ç—å roc_auc –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ probas)
            y_score = np.asarray(y_pred, dtype=float).ravel()

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ —á–∏—Å–ª–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫
    y_pred = np.asarray(y_pred).astype(int).ravel().tolist()

    # --- 10. –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ (–≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ compute_classification_metrics) ---
    print("|- –®–∞–≥ 7: –†–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫...")
    metrics = compute_classification_metrics(
        y_true=y_test,
        y_pred=y_pred,
        y_score=y_score,
        report_dir=REPORTS_DIR,
        metrics_path=METRICS_PATH
    )
    print("|-- –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ:")
    for name, value in metrics.items():
        print(f"|--  {name}: {value if value is not None else 'N/A'}")
    print(f"|-- –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {METRICS_PATH}")

    # --- 11. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –≤—Å—ë–º –¥–∞—Ç–∞—Å–µ—Ç–µ ---
    print("|- –®–∞–≥ 8: –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    X_full = df[ORIGINAL_TEXT_COLUMN].values
    y_full = df[ORIGINAL_LABEL_COLUMN].values
    final_model = SentimentClassifier()
    final_model.fit(X_full, y_full)

    # --- 12. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (—Å –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –µ—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –µ—Å—Ç—å) ---
    print("|- –®–∞–≥ 9: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    final_model_path = FINAL_MODEL_PATH
    if final_model_path.exists():
        print("|-- –§–∞–π–ª —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç!")
        MODEL_NAME = FINAL_MODEL_PATH.stem
        MODEL_format = FINAL_MODEL_PATH.suffix.lstrip('.')
        # –ü–æ–≤–µ–¥–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: –¥–æ–±–∞–≤–ª—è–µ–º _vN –ø–µ—Ä–µ–¥ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
        m = re.search(r"(.*)_v(\d+)$", MODEL_NAME)
        if m:
            base = m.group(1)
            version = int(m.group(2)) + 1
        else:
            base = MODEL_NAME
            version = 2
        new_filename = f"{base}_v{version}.{MODEL_format}"
        final_model_path = final_model_path.parent / new_filename
        print(f"|-- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏ –∫–∞–∫: {final_model_path}")

    final_model.save_model(str(final_model_path))
    print(f"|-- –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {final_model_path}")

    print("\nüéâ –ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à—ë–Ω! –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω—ã.")


if __name__ == "__main__":
    main()